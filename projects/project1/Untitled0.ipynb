{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [],
   "mount_file_id": "1zhX8GShLe2lH7m50f14tR3zG2_ycThQA",
   "authorship_tag": "ABX9TyMOtG+aZIqqfSobohdvDotQ"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G67AsBmfHrj_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1666370680568,
     "user_tz": -120,
     "elapsed": 483,
     "user": {
      "displayName": "Yitao Xu",
      "userId": "08412486466278411597"
     }
    },
    "outputId": "abc7ff93-b074-4dd1-dcf8-e9aa9d0b170f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/drive/MyDrive/EPFL_course_project/MLCS433/ML-Project1\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/EPFL_course_project/MLCS433/ML-Project1/"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import data_utils\n",
    "import implementations\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "id": "GJeFp3FYIgLv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1666370681663,
     "user_tz": -120,
     "elapsed": 458,
     "user": {
      "displayName": "Yitao Xu",
      "userId": "08412486466278411597"
     }
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_data, train_label = data_utils.load_data('Data/train.csv')\n",
    "train_data.shape, train_label.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VYLUX1wsmWDM",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1666370692630,
     "user_tz": -120,
     "elapsed": 10973,
     "user": {
      "displayName": "Yitao Xu",
      "userId": "08412486466278411597"
     }
    },
    "outputId": "8f0ba769-8617-4834-f1af-88af8a2cc91f"
   },
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "((250000, 30), (250000,))"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def cross_validation(train_data, train_label, k_fold, eval_func, input_dict):\n",
    "  data_num = train_data.shape[0]\n",
    "  data_dim = train_data.shape[1]\n",
    "  fold_part_idx = data_utils.k_fold(data_num, k_fold)\n",
    "\n",
    "  loss_list = []\n",
    "  acc_list = []\n",
    "  for k in range(k_fold): \n",
    "    cur_train_idx = np.concatenate([fold_part_idx[:k, :], fold_part_idx[k+1:, :]], axis = 0)\n",
    "    cur_train_idx = cur_train_idx.flatten()\n",
    "    cur_test_idx = fold_part_idx[k, :]\n",
    "    x_tr = train_data[cur_train_idx, :]\n",
    "    x_te = train_data[cur_test_idx, :]\n",
    "    y_tr = train_label[cur_train_idx]\n",
    "    y_te = train_label[cur_test_idx]\n",
    "\n",
    "    w, loss = eval_func(y_tr, x_tr,  **input_dict)\n",
    "    _, train_acc = implementations.compute_statistics_all(y_tr, x_tr, w, func_type = input_dict['func_type'])\n",
    "    test_loss, test_acc = implementations.compute_statistics_all(y_te, x_te, w, func_type = input_dict['func_type'])\n",
    "    loss_list.append(test_loss)\n",
    "    acc_list.append(test_acc)\n",
    "    # print(test_acc)\n",
    "  return np.mean(loss_list), np.mean(acc_list)"
   ],
   "metadata": {
    "id": "7W8Ec61qYtNR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1666370908291,
     "user_tz": -120,
     "elapsed": 660,
     "user": {
      "displayName": "Yitao Xu",
      "userId": "08412486466278411597"
     }
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "group_num = 2\n",
    "k_fold_num = 5"
   ],
   "metadata": {
    "id": "1jzOc5FGi4T-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1666370700185,
     "user_tz": -120,
     "elapsed": 9,
     "user": {
      "displayName": "Yitao Xu",
      "userId": "08412486466278411597"
     }
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "max_acc = 0\n",
    "lambdas = np.logspace(-10, 0, 10)\n",
    "test_func = implementations.least_squares\n",
    "for clean in [1]:\n",
    "  for poly in [0,1]:\n",
    "    if(poly):\n",
    "      for degree in [3,4,8,9]:\n",
    "        degree_list = [1] * 3\n",
    "        degree_list[group_num] = degree\n",
    "        for normalize in [1]:\n",
    "          for all_poly in [True, False]:\n",
    "            group0_x, group0_labels, group1_x, group1_labels, group2_x, group2_labels = \\\n",
    "                          data_utils.process_data(train_data, train_label, clean = clean)\n",
    "            group0_x, group1_x, group2_x = \\\n",
    "                    data_utils.group_poly(group0_x, group1_x, group2_x, degree_list, all_poly)\n",
    "            cur_group = [group0_x, group1_x, group2_x]\n",
    "            cur_labels = [group0_labels, group1_labels, group2_labels]\n",
    "            group_x = cur_group[group_num]\n",
    "            group_label = cur_labels[group_num]\n",
    "            if(normalize):\n",
    "              group_x = data_utils.normalize(group_x)\n",
    "            \n",
    "            input_dict = {'lambda_':0, \\\n",
    "                    'initial_w':np.zeros(group_x.shape[1]), \\\n",
    "                    'max_iters':10000, \\\n",
    "                    'gamma':0.001, \\\n",
    "                    'sgd':False, \\\n",
    "                    'func_type':'linear'}\n",
    "            # try:\n",
    "            loss, acc = cross_validation(group_x, group_label, k_fold_num, test_func, input_dict)\n",
    "            # except:\n",
    "            #   print(f'Wrong. \\\n",
    "            #       Clean:{clean}, \\\n",
    "            #       Poly:{poly}, \\\n",
    "            #       Degree:{degree}, \\\n",
    "            #       Normalize: {normalize}, \\\n",
    "            #       all_poly:{all_poly}')\n",
    "            #   continue\n",
    "            if(acc > max_acc):\n",
    "              print(f'Found a better scheme. \\\n",
    "                  Clean:{clean}, \\\n",
    "                  Poly:{poly}, \\\n",
    "                  Degree:{degree}, \\\n",
    "                  Normalize: {normalize}, \\\n",
    "                  all_poly:{all_poly}, \\\n",
    "                  Acc:{acc}')\n",
    "              max_acc = acc\n",
    "    else:\n",
    "      for normalize in [0, 1]:\n",
    "        group0_x, group0_labels, group1_x, group1_labels, group2_x, group2_labels = \\\n",
    "                      data_utils.process_data(train_data, train_label, clean = clean)\n",
    "        cur_group = [group0_x, group1_x, group2_x]\n",
    "        cur_labels = [group0_labels, group1_labels, group2_labels]\n",
    "        group_x = cur_group[group_num]\n",
    "        group_label = cur_labels[group_num]\n",
    "        if(normalize):\n",
    "          group_x = data_utils.normalize(group_x)\n",
    "        input_dict = {'lambda_':0, \\\n",
    "                'initial_w':np.zeros(group_x.shape[1]), \\\n",
    "                'max_iters':10000, \\\n",
    "                'gamma':0.001, \\\n",
    "                'sgd':False, \\\n",
    "                'func_type':'linear'}\n",
    "        try:\n",
    "          loss, acc = cross_validation(group_x, group_label, k_fold_num, test_func, input_dict)\n",
    "        except:\n",
    "          print(f'Wrong. \\\n",
    "              Clean:{clean}, \\\n",
    "              Poly:{poly}, \\\n",
    "              Normalize: {normalize}')\n",
    "          continue\n",
    "        if(acc > max_acc):\n",
    "          print(f'Found a better scheme. \\\n",
    "              Clean:{clean}, \\\n",
    "              Poly:{poly}, \\\n",
    "              Normalize: {normalize}, \\\n",
    "              Acc:{acc}')\n",
    "          max_acc = acc"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-OPcEO4FERhn",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1666370777455,
     "user_tz": -120,
     "elapsed": 30419,
     "user": {
      "displayName": "Yitao Xu",
      "userId": "08412486466278411597"
     }
    },
    "outputId": "3eade338-c9b1-43e2-82ec-06396fa8282d"
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong.               Clean:1,               Poly:0,               Normalize: 0\n",
      "Wrong.               Clean:1,               Poly:0,               Normalize: 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "least_squares() got an unexpected keyword argument 'initial_w'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [9]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     23\u001B[0m input_dict \u001B[38;5;241m=\u001B[39m { \\\n\u001B[1;32m     24\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minitial_w\u001B[39m\u001B[38;5;124m'\u001B[39m:np\u001B[38;5;241m.\u001B[39mzeros(group_x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]), \\\n\u001B[1;32m     25\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_iters\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;241m10000\u001B[39m, \\\n\u001B[1;32m     26\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgamma\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;241m0.001\u001B[39m, \\\n\u001B[1;32m     27\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msgd\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;28;01mFalse\u001B[39;00m, \\\n\u001B[1;32m     28\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfunc_type\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlinear\u001B[39m\u001B[38;5;124m'\u001B[39m}\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# try:\u001B[39;00m\n\u001B[0;32m---> 30\u001B[0m loss, acc \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgroup_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup_label\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk_fold_num\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;66;03m# except:\u001B[39;00m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;66;03m#   print(f'Wrong. \\\u001B[39;00m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;66;03m#       Clean:{clean}, \\\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m#       all_poly:{all_poly}')\u001B[39;00m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;66;03m#   continue\u001B[39;00m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m(acc \u001B[38;5;241m>\u001B[39m max_acc):\n",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36mcross_validation\u001B[0;34m(train_data, train_label, k_fold, eval_func, input_dict)\u001B[0m\n\u001B[1;32m     14\u001B[0m y_tr \u001B[38;5;241m=\u001B[39m train_label[cur_train_idx]\n\u001B[1;32m     15\u001B[0m y_te \u001B[38;5;241m=\u001B[39m train_label[cur_test_idx]\n\u001B[0;32m---> 17\u001B[0m w, loss \u001B[38;5;241m=\u001B[39m \u001B[43meval_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_tr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_tr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minput_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m _, train_acc \u001B[38;5;241m=\u001B[39m implementations\u001B[38;5;241m.\u001B[39mcompute_statistics_all(y_tr, x_tr, w, func_type \u001B[38;5;241m=\u001B[39m input_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfunc_type\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     19\u001B[0m test_loss, test_acc \u001B[38;5;241m=\u001B[39m implementations\u001B[38;5;241m.\u001B[39mcompute_statistics_all(y_te, x_te, w, func_type \u001B[38;5;241m=\u001B[39m input_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfunc_type\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "\u001B[0;31mTypeError\u001B[0m: least_squares() got an unexpected keyword argument 'initial_w'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "max_acc = 0\n",
    "lambdas = np.logspace(-10, 0, 10)\n",
    "test_func = implementations.ridge_regression\n",
    "for clean in [1]:\n",
    "  for poly in [1]:\n",
    "    if(poly):\n",
    "      for degree in [9]:\n",
    "        degree_list = [1] * 3\n",
    "        degree_list[group_num] = degree\n",
    "        for normalize in [1]:\n",
    "          for all_poly in [True, False]:\n",
    "            group0_x, group0_labels, group1_x, group1_labels, group2_x, group2_labels = \\\n",
    "                          data_utils.process_data(train_data, train_label, clean = clean)\n",
    "            group0_x, group1_x, group2_x = \\\n",
    "                    data_utils.group_poly(group0_x, group1_x, group2_x, degree_list, all_poly)\n",
    "            cur_group = [group0_x, group1_x, group2_x]\n",
    "            cur_labels = [group0_labels, group1_labels, group2_labels]\n",
    "            group_x = cur_group[group_num]\n",
    "            group_label = cur_labels[group_num]\n",
    "            if(normalize):\n",
    "              group_x = data_utils.normalize(group_x)\n",
    "            \n",
    "            for lambda_ in lambdas:\n",
    "              input_dict = {'lambda_':lambda_, \\\n",
    "                      'initial_w':np.zeros(group_x.shape[1]), \\\n",
    "                      'max_iters':10000, \\\n",
    "                      'gamma':0.001, \\\n",
    "                      'sgd':False, \\\n",
    "                      'func_type':'linear'}\n",
    "              loss, acc = cross_validation(group_x, group_label, k_fold_num, test_func, input_dict)\n",
    "              print(acc)\n",
    "              if(acc > max_acc):\n",
    "                print(f'Found a better scheme. \\\n",
    "                    Clean:{clean}, \\\n",
    "                    Poly:{poly}, \\\n",
    "                    Degree:{degree}, \\\n",
    "                    Normalize: {normalize}, \\\n",
    "                    lambda:{lambda_}, \\\n",
    "                    all_poly:{all_poly}, \\\n",
    "                    Acc:{acc}')\n",
    "                max_acc = acc\n",
    "    else:\n",
    "      for normalize in [0, 1]:\n",
    "        group0_x, group0_labels, group1_x, group1_labels, group2_x, group2_labels = \\\n",
    "                      data_utils.process_data(train_data, train_label, clean = clean)\n",
    "        cur_group = [group0_x, group1_x, group2_x]\n",
    "        cur_labels = [group0_labels, group1_labels, group2_labels]\n",
    "        group_x = cur_group[group_num]\n",
    "        group_label = cur_labels[group_num]\n",
    "        if(normalize):\n",
    "          group_x = data_utils.normalize(group_x)\n",
    "        for lambda_ in lambdas:\n",
    "          input_dict = {'lambda_':lambda_, \\\n",
    "                  'initial_w':np.zeros(group_x.shape[1]), \\\n",
    "                  'max_iters':10000, \\\n",
    "                  'gamma':0.001, \\\n",
    "                  'sgd':False, \\\n",
    "                  'func_type':'linear'}\n",
    "          loss, acc = cross_validation(group_x, group_label, k_fold_num, test_func, input_dict)\n",
    "          if(acc > max_acc):\n",
    "            print(f'Found a better scheme. \\\n",
    "                Clean:{clean}, \\\n",
    "                Poly:{poly}, \\\n",
    "                Normalize: {normalize}, \\\n",
    "                lambda:{lambda_}, \\\n",
    "                Acc:{acc}')\n",
    "            max_acc = acc"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WNoyC9jQZskS",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1666370953143,
     "user_tz": -120,
     "elapsed": 28208,
     "user": {
      "displayName": "Yitao Xu",
      "userId": "08412486466278411597"
     }
    },
    "outputId": "80012ced-4ef5-4d62-c312-0c1ff42278a5"
   },
   "execution_count": 10,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ridge_regression() got an unexpected keyword argument 'initial_w'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [10]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m lambda_ \u001B[38;5;129;01min\u001B[39;00m lambdas:\n\u001B[1;32m     24\u001B[0m   input_dict \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlambda_\u001B[39m\u001B[38;5;124m'\u001B[39m:lambda_, \\\n\u001B[1;32m     25\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minitial_w\u001B[39m\u001B[38;5;124m'\u001B[39m:np\u001B[38;5;241m.\u001B[39mzeros(group_x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]), \\\n\u001B[1;32m     26\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_iters\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;241m10000\u001B[39m, \\\n\u001B[1;32m     27\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgamma\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;241m0.001\u001B[39m, \\\n\u001B[1;32m     28\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msgd\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;28;01mFalse\u001B[39;00m, \\\n\u001B[1;32m     29\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfunc_type\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlinear\u001B[39m\u001B[38;5;124m'\u001B[39m}\n\u001B[0;32m---> 30\u001B[0m   loss, acc \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgroup_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup_label\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk_fold_num\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m   \u001B[38;5;28mprint\u001B[39m(acc)\n\u001B[1;32m     32\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m(acc \u001B[38;5;241m>\u001B[39m max_acc):\n",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36mcross_validation\u001B[0;34m(train_data, train_label, k_fold, eval_func, input_dict)\u001B[0m\n\u001B[1;32m     14\u001B[0m y_tr \u001B[38;5;241m=\u001B[39m train_label[cur_train_idx]\n\u001B[1;32m     15\u001B[0m y_te \u001B[38;5;241m=\u001B[39m train_label[cur_test_idx]\n\u001B[0;32m---> 17\u001B[0m w, loss \u001B[38;5;241m=\u001B[39m \u001B[43meval_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_tr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_tr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minput_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m _, train_acc \u001B[38;5;241m=\u001B[39m implementations\u001B[38;5;241m.\u001B[39mcompute_statistics_all(y_tr, x_tr, w, func_type \u001B[38;5;241m=\u001B[39m input_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfunc_type\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     19\u001B[0m test_loss, test_acc \u001B[38;5;241m=\u001B[39m implementations\u001B[38;5;241m.\u001B[39mcompute_statistics_all(y_te, x_te, w, func_type \u001B[38;5;241m=\u001B[39m input_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfunc_type\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "\u001B[0;31mTypeError\u001B[0m: ridge_regression() got an unexpected keyword argument 'initial_w'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "max_acc = 0\n",
    "lambdas = np.logspace(-10, 0, 10)\n",
    "gammas = [0.015]\n",
    "iters = [1000]\n",
    "test_func = implementations.reg_logistic_regression\n",
    "for clean in [1]:\n",
    "  for poly in [1]:\n",
    "    if(poly):\n",
    "      for degree in [3]:\n",
    "        degree_list = [1] * 3\n",
    "        degree_list[group_num] = degree\n",
    "        for normalize in [1]:\n",
    "          for all_poly in [True, False]:\n",
    "            group0_x, group0_labels, group1_x, group1_labels, group2_x, group2_labels = \\\n",
    "                          data_utils.process_data(train_data, train_label, clean = clean)\n",
    "            group0_x, group1_x, group2_x = \\\n",
    "                    data_utils.group_poly(group0_x, group1_x, group2_x, degree_list, all_poly)\n",
    "            cur_group = [group0_x, group1_x, group2_x]\n",
    "            cur_labels = [group0_labels, group1_labels, group2_labels]\n",
    "            group_x = cur_group[group_num]\n",
    "            group_label = cur_labels[group_num]\n",
    "            group_label[group_label == -1] = 0\n",
    "            if(normalize):\n",
    "              group_x = data_utils.normalize(group_x)\n",
    "            \n",
    "            for gamma in gammas:\n",
    "              for iteration in iters:\n",
    "                input_dict = {'lambda_':0.00000001, \\\n",
    "                        'initial_w':np.zeros(group_x.shape[1]), \\\n",
    "                        'max_iters':iteration, \\\n",
    "                        'gamma':gamma, \\\n",
    "                        'sgd':False, \\\n",
    "                        'func_type':'logistic'}\n",
    "                \n",
    "                loss, acc = cross_validation(group_x, group_label, k_fold_num, test_func, input_dict)\n",
    "                if(acc > max_acc):\n",
    "                  print(f'Found a better scheme. \\\n",
    "                      Clean:{clean}, \\\n",
    "                      Poly:{poly}, \\\n",
    "                      Degree:{degree}, \\\n",
    "                      Normalize: {normalize}, \\\n",
    "                      all_poly:{all_poly}, \\\n",
    "                      gamma:{gamma},\\\n",
    "                      iteration:{iteration},\\\n",
    "                      Acc:{acc}')\n",
    "                  max_acc = acc\n",
    "    else:\n",
    "      for normalize in [0, 1]:\n",
    "        group0_x, group0_labels, group1_x, group1_labels, group2_x, group2_labels = \\\n",
    "                      data_utils.process_data(train_data, train_label, clean = clean)\n",
    "        cur_group = [group0_x, group1_x, group2_x]\n",
    "        cur_labels = [group0_labels, group1_labels, group2_labels]\n",
    "        group_x = cur_group[group_num]\n",
    "        group_label = cur_labels[group_num]\n",
    "        group_label[np.where(group_label == -1)] = 0\n",
    "        if(normalize):\n",
    "          group_x = data_utils.normalize(group_x)\n",
    "        for gamma in gammas:\n",
    "          for iteration in iters:\n",
    "            input_dict = {'lambda_':0.01, \\\n",
    "                    'initial_w':np.zeros(group_x.shape[1]), \\\n",
    "                    'max_iters':iteration, \\\n",
    "                    'gamma':gamma, \\\n",
    "                    'sgd':False, \\\n",
    "                    'func_type':'logistic'}\n",
    "            loss, acc = cross_validation(group_x, group_label, k_fold_num, test_func, input_dict)\n",
    "            if(acc > max_acc):\n",
    "              print(f'Found a better scheme. \\\n",
    "                  Clean:{clean}, \\\n",
    "                  Poly:{poly}, \\\n",
    "                  Degree:No, \\\n",
    "                  Normalize: {normalize}, \\\n",
    "                  gamma:{gamma},\\\n",
    "                  iteration:{iteration},\\\n",
    "                  Acc:{acc}')\n",
    "              max_acc = acc"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DpXBteAhIdqD",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1666369819740,
     "user_tz": -120,
     "elapsed": 78598,
     "user": {
      "displayName": "Yitao Xu",
      "userId": "08412486466278411597"
     }
    },
    "outputId": "29af2524-22cc-400d-b834-46ae8500b01a"
   },
   "execution_count": 11,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "reg_logistic_regression() got an unexpected keyword argument 'func_type'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m iteration \u001B[38;5;129;01min\u001B[39;00m iters:\n\u001B[1;32m     28\u001B[0m   input_dict \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlambda_\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;241m0.00000001\u001B[39m, \\\n\u001B[1;32m     29\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minitial_w\u001B[39m\u001B[38;5;124m'\u001B[39m:np\u001B[38;5;241m.\u001B[39mzeros(group_x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]), \\\n\u001B[1;32m     30\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_iters\u001B[39m\u001B[38;5;124m'\u001B[39m:iteration, \\\n\u001B[1;32m     31\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgamma\u001B[39m\u001B[38;5;124m'\u001B[39m:gamma, \\\n\u001B[1;32m     32\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msgd\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;28;01mFalse\u001B[39;00m, \\\n\u001B[1;32m     33\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfunc_type\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlogistic\u001B[39m\u001B[38;5;124m'\u001B[39m}\n\u001B[0;32m---> 35\u001B[0m   loss, acc \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgroup_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup_label\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk_fold_num\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m(acc \u001B[38;5;241m>\u001B[39m max_acc):\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFound a better scheme. \u001B[39m\u001B[38;5;130;01m\\\u001B[39;00m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;124m        Clean:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclean\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;130;01m\\\u001B[39;00m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;124m        Poly:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpoly\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;130;01m\\\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;124m        iteration:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00miteration\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m,\u001B[39m\u001B[38;5;130;01m\\\u001B[39;00m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;124m        Acc:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00macc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36mcross_validation\u001B[0;34m(train_data, train_label, k_fold, eval_func, input_dict)\u001B[0m\n\u001B[1;32m     14\u001B[0m y_tr \u001B[38;5;241m=\u001B[39m train_label[cur_train_idx]\n\u001B[1;32m     15\u001B[0m y_te \u001B[38;5;241m=\u001B[39m train_label[cur_test_idx]\n\u001B[0;32m---> 17\u001B[0m w, loss \u001B[38;5;241m=\u001B[39m \u001B[43meval_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_tr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_tr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minput_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m _, train_acc \u001B[38;5;241m=\u001B[39m implementations\u001B[38;5;241m.\u001B[39mcompute_statistics_all(y_tr, x_tr, w, func_type \u001B[38;5;241m=\u001B[39m input_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfunc_type\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     19\u001B[0m test_loss, test_acc \u001B[38;5;241m=\u001B[39m implementations\u001B[38;5;241m.\u001B[39mcompute_statistics_all(y_te, x_te, w, func_type \u001B[38;5;241m=\u001B[39m input_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfunc_type\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "\u001B[0;31mTypeError\u001B[0m: reg_logistic_regression() got an unexpected keyword argument 'func_type'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "max_acc = 0\n",
    "lambdas = np.logspace(-10, 0, 10)\n",
    "gammas = [0.01]\n",
    "iters = [1000]\n",
    "test_func = implementations.mean_squared_error_gd\n",
    "for clean in [1]:\n",
    "  for poly in [1]:\n",
    "    if(poly):\n",
    "      for degree in [3]:\n",
    "        degree_list = [1] * 3\n",
    "        degree_list[group_num] = degree\n",
    "        for normalize in [1]:\n",
    "          for all_poly in [True, False]:\n",
    "            group0_x, group0_labels, group1_x, group1_labels, group2_x, group2_labels = \\\n",
    "                          data_utils.process_data(train_data, train_label, clean = clean)\n",
    "            group0_x, group1_x, group2_x = \\\n",
    "                    data_utils.group_poly(group0_x, group1_x, group2_x, degree_list, all_poly)\n",
    "            cur_group = [group0_x, group1_x, group2_x]\n",
    "            cur_labels = [group0_labels, group1_labels, group2_labels]\n",
    "            group_x = cur_group[group_num]\n",
    "            group_label = cur_labels[group_num]\n",
    "            if(normalize):\n",
    "              group_x = data_utils.normalize(group_x)\n",
    "            \n",
    "            for gamma in gammas:\n",
    "              for iteration in iters:\n",
    "                input_dict = {'lambda_':0.00000001, \\\n",
    "                        'initial_w':np.zeros(group_x.shape[1]), \\\n",
    "                        'max_iters':iteration, \\\n",
    "                        'gamma':gamma, \\\n",
    "                        'sgd':False, \\\n",
    "                        'func_type':'linear'}\n",
    "                \n",
    "                loss, acc = cross_validation(group_x, group_label, k_fold_num, test_func, input_dict)\n",
    "                if(acc > max_acc):\n",
    "                  print(f'Found a better scheme. \\\n",
    "                      Clean:{clean}, \\\n",
    "                      Poly:{poly}, \\\n",
    "                      Degree:{degree}, \\\n",
    "                      Normalize: {normalize}, \\\n",
    "                      all_poly:{all_poly}, \\\n",
    "                      gamma:{gamma},\\\n",
    "                      iteration:{iteration},\\\n",
    "                      Acc:{acc}')\n",
    "                  max_acc = acc\n",
    "    else:\n",
    "      for normalize in [0, 1]:\n",
    "        group0_x, group0_labels, group1_x, group1_labels, group2_x, group2_labels = \\\n",
    "                      data_utils.process_data(train_data, train_label, clean = clean)\n",
    "        cur_group = [group0_x, group1_x, group2_x]\n",
    "        cur_labels = [group0_labels, group1_labels, group2_labels]\n",
    "        group_x = cur_group[group_num]\n",
    "        group_label = cur_labels[group_num]\n",
    "        if(normalize):\n",
    "          group_x = data_utils.normalize(group_x)\n",
    "        for gamma in gammas:\n",
    "          for iteration in iters:\n",
    "            input_dict = {'lambda_':0.01, \\\n",
    "                    'initial_w':np.zeros(group_x.shape[1]), \\\n",
    "                    'max_iters':iteration, \\\n",
    "                    'gamma':gamma, \\\n",
    "                    'sgd':False, \\\n",
    "                    'func_type':'linear'}\n",
    "            loss, acc = cross_validation(group_x, group_label, k_fold_num, test_func, input_dict)\n",
    "            if(acc > max_acc):\n",
    "              print(f'Found a better scheme. \\\n",
    "                  Clean:{clean}, \\\n",
    "                  Poly:{poly}, \\\n",
    "                  Degree:No, \\\n",
    "                  Normalize: {normalize}, \\\n",
    "                  gamma:{gamma},\\\n",
    "                  iteration:{iteration},\\\n",
    "                  Acc:{acc}')\n",
    "              max_acc = acc"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "id": "T2cd4oDSYsyW",
    "executionInfo": {
     "status": "error",
     "timestamp": 1666370136299,
     "user_tz": -120,
     "elapsed": 38439,
     "user": {
      "displayName": "Yitao Xu",
      "userId": "08412486466278411597"
     }
    },
    "outputId": "4bf057ec-6e5a-4da6-bc0f-aa71f44c8970"
   },
   "execution_count": 12,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mean_squared_error_gd() got an unexpected keyword argument 'lambda_'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [12]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m iteration \u001B[38;5;129;01min\u001B[39;00m iters:\n\u001B[1;32m     27\u001B[0m   input_dict \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlambda_\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;241m0.00000001\u001B[39m, \\\n\u001B[1;32m     28\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minitial_w\u001B[39m\u001B[38;5;124m'\u001B[39m:np\u001B[38;5;241m.\u001B[39mzeros(group_x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]), \\\n\u001B[1;32m     29\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_iters\u001B[39m\u001B[38;5;124m'\u001B[39m:iteration, \\\n\u001B[1;32m     30\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgamma\u001B[39m\u001B[38;5;124m'\u001B[39m:gamma, \\\n\u001B[1;32m     31\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msgd\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;28;01mFalse\u001B[39;00m, \\\n\u001B[1;32m     32\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfunc_type\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlinear\u001B[39m\u001B[38;5;124m'\u001B[39m}\n\u001B[0;32m---> 34\u001B[0m   loss, acc \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgroup_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup_label\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk_fold_num\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m(acc \u001B[38;5;241m>\u001B[39m max_acc):\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFound a better scheme. \u001B[39m\u001B[38;5;130;01m\\\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;124m        Clean:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclean\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;130;01m\\\u001B[39;00m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;124m        Poly:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpoly\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;130;01m\\\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;124m        iteration:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00miteration\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m,\u001B[39m\u001B[38;5;130;01m\\\u001B[39;00m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;124m        Acc:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00macc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36mcross_validation\u001B[0;34m(train_data, train_label, k_fold, eval_func, input_dict)\u001B[0m\n\u001B[1;32m     14\u001B[0m y_tr \u001B[38;5;241m=\u001B[39m train_label[cur_train_idx]\n\u001B[1;32m     15\u001B[0m y_te \u001B[38;5;241m=\u001B[39m train_label[cur_test_idx]\n\u001B[0;32m---> 17\u001B[0m w, loss \u001B[38;5;241m=\u001B[39m \u001B[43meval_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_tr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_tr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minput_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m _, train_acc \u001B[38;5;241m=\u001B[39m implementations\u001B[38;5;241m.\u001B[39mcompute_statistics_all(y_tr, x_tr, w, func_type \u001B[38;5;241m=\u001B[39m input_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfunc_type\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     19\u001B[0m test_loss, test_acc \u001B[38;5;241m=\u001B[39m implementations\u001B[38;5;241m.\u001B[39mcompute_statistics_all(y_te, x_te, w, func_type \u001B[38;5;241m=\u001B[39m input_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfunc_type\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "\u001B[0;31mTypeError\u001B[0m: mean_squared_error_gd() got an unexpected keyword argument 'lambda_'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "JcnB3DNpyAic"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}